{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\n#import matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import accuracy_score, log_loss","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T06:42:38.226394Z","iopub.execute_input":"2025-09-21T06:42:38.226696Z","iopub.status.idle":"2025-09-21T06:42:38.231345Z","shell.execute_reply.started":"2025-09-21T06:42:38.226676Z","shell.execute_reply":"2025-09-21T06:42:38.230399Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"random_number_genrator = np.random.default_rng(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T06:42:38.232709Z","iopub.execute_input":"2025-09-21T06:42:38.232959Z","iopub.status.idle":"2025-09-21T06:42:38.250096Z","shell.execute_reply.started":"2025-09-21T06:42:38.232938Z","shell.execute_reply":"2025-09-21T06:42:38.249064Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"def online_learning_streaming(n_batchs = 50,\n                             batch_sizes = 2048,\n                             n_features = 25, \n                             drift = 10):\n    mean0_a, mean1_a = np.zeros(n_features), np.ones(n_features)*0.25\n    mean0_b, mean1_b = np.ones(n_features)*-0.25, np.ones(n_features)\n    cov = np.eye(n_features) * 1.0\n\n\n    for b in range(n_batchs):\n        mean0 = mean0_a if b< drift else mean0_b\n        mean1 = mean1_a if b < drift else mean1_b\n\n        number0 = batch_sizes //2 \n        number1 = batch_sizes -  number0\n    \n        data0 = random_number_genrator.multivariate_normal(mean0, cov, size = number0)\n        data1 = random_number_genrator.multivariate_normal(mean1, cov, size = number1)\n    \n    \n        X = np.vstack([data0, data1])\n        y = np.hstack([np.zeros(number0, dtype = int), np.ones(number1, dtype = int)])\n    \n    \n    \n        index = random_number_genrator.permutation(len(y))\n    \n        yield X[index], y[index], b","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T06:42:38.251626Z","iopub.execute_input":"2025-09-21T06:42:38.251998Z","iopub.status.idle":"2025-09-21T06:42:38.269376Z","shell.execute_reply.started":"2025-09-21T06:42:38.251968Z","shell.execute_reply":"2025-09-21T06:42:38.268232Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"def online_learning_streaming_classification(n_batchs = 50,\n                                            batch_size = 2048, \n                                            n_features = 25):\n    scaling_method = StandardScaler()\n    classification_model = SGDClassifier(loss = \"log_loss\", \n                                        learning_rate = \"optimal\",\n                                        alpha  = 1e-4,\n                                        random_state = 42)\n    classes = np.array([0, 1])\n    for x, y, b in online_learning_streaming(n_batchs = n_batchs,batch_sizes = batch_size,n_features = n_features):\n        scaling_method.partial_fit(x)\n        scaling_method_x = scaling_method.transform(x) \n\n\n        if b == 0:\n            classification_model.partial_fit(scaling_method_x, y, classes = classes)\n        else:\n            classification_model.partial_fit(scaling_method_x, y)\n\n\n        probability = classification_model.predict_proba(scaling_method_x)\n        model_predictions = probability.argmax(axis = 1)\n\n\n        accuracy = accuracy_score(y,  model_predictions)\n        loss = log_loss(y, probability, labels = classes)\n\n        print(f\"Model Current Batch: {b:03d}---- Accuracy: {accuracy:.3f} ---- Loss: {loss:.3f}\")\n\n    return scaling_method, classification_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T06:44:41.087337Z","iopub.execute_input":"2025-09-21T06:44:41.087663Z","iopub.status.idle":"2025-09-21T06:44:41.094840Z","shell.execute_reply.started":"2025-09-21T06:44:41.087639Z","shell.execute_reply":"2025-09-21T06:44:41.093918Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    scaling_method, classification_model = online_learning_streaming_classification(n_batchs = 50,\n                                            batch_size = 2048, \n                                            n_features = 25)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T06:44:41.436853Z","iopub.execute_input":"2025-09-21T06:44:41.437183Z","iopub.status.idle":"2025-09-21T06:44:41.785074Z","shell.execute_reply.started":"2025-09-21T06:44:41.437161Z","shell.execute_reply":"2025-09-21T06:44:41.784170Z"}},"outputs":[{"name":"stdout","text":"Model Current Batch: 000---- Accuracy: 0.631 ---- Loss: 9.677\nModel Current Batch: 001---- Accuracy: 0.606 ---- Loss: 7.470\nModel Current Batch: 002---- Accuracy: 0.656 ---- Loss: 5.522\nModel Current Batch: 003---- Accuracy: 0.594 ---- Loss: 5.820\nModel Current Batch: 004---- Accuracy: 0.646 ---- Loss: 3.742\nModel Current Batch: 005---- Accuracy: 0.682 ---- Loss: 2.898\nModel Current Batch: 006---- Accuracy: 0.683 ---- Loss: 2.423\nModel Current Batch: 007---- Accuracy: 0.640 ---- Loss: 2.393\nModel Current Batch: 008---- Accuracy: 0.652 ---- Loss: 1.983\nModel Current Batch: 009---- Accuracy: 0.657 ---- Loss: 2.132\nModel Current Batch: 010---- Accuracy: 1.000 ---- Loss: 0.003\nModel Current Batch: 011---- Accuracy: 0.999 ---- Loss: 0.004\nModel Current Batch: 012---- Accuracy: 0.999 ---- Loss: 0.002\nModel Current Batch: 013---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 014---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 015---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 016---- Accuracy: 1.000 ---- Loss: 0.000\nModel Current Batch: 017---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 018---- Accuracy: 1.000 ---- Loss: 0.002\nModel Current Batch: 019---- Accuracy: 1.000 ---- Loss: 0.000\nModel Current Batch: 020---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 021---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 022---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 023---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 024---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 025---- Accuracy: 1.000 ---- Loss: 0.002\nModel Current Batch: 026---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 027---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 028---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 029---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 030---- Accuracy: 1.000 ---- Loss: 0.003\nModel Current Batch: 031---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 032---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 033---- Accuracy: 1.000 ---- Loss: 0.002\nModel Current Batch: 034---- Accuracy: 1.000 ---- Loss: 0.003\nModel Current Batch: 035---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 036---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 037---- Accuracy: 1.000 ---- Loss: 0.002\nModel Current Batch: 038---- Accuracy: 1.000 ---- Loss: 0.002\nModel Current Batch: 039---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 040---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 041---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 042---- Accuracy: 1.000 ---- Loss: 0.002\nModel Current Batch: 043---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 044---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 045---- Accuracy: 1.000 ---- Loss: 0.002\nModel Current Batch: 046---- Accuracy: 1.000 ---- Loss: 0.002\nModel Current Batch: 047---- Accuracy: 1.000 ---- Loss: 0.003\nModel Current Batch: 048---- Accuracy: 1.000 ---- Loss: 0.001\nModel Current Batch: 049---- Accuracy: 1.000 ---- Loss: 0.002\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}